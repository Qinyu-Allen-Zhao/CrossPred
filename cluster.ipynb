{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "np.random.seed(81021)\n",
    "\n",
    "with open(\"./data/result_summary.json\", 'r') as f:\n",
    "    result_summary = json.load(f)\n",
    "\n",
    "result_summary = pd.DataFrame(result_summary).T\n",
    "res_mat = result_summary.values\n",
    "res_mat = (res_mat - np.mean(res_mat, axis=0, keepdims=True)) / np.std(res_mat, axis=0, keepdims=True)\n",
    "\n",
    "res_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(data, n_clusters):\n",
    "    X = data.copy()\n",
    "\n",
    "    sse = []\n",
    "    for k in range(1, 11):\n",
    "        kmeans = KMeans(n_clusters=k)\n",
    "        kmeans.fit(X)\n",
    "        sse.append(kmeans.inertia_)\n",
    "\n",
    "    plt.plot(range(1, 11), sse, marker='o')\n",
    "    plt.title('Elbow Method')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('SSE')\n",
    "    plt.show()\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    kmeans.fit(X)\n",
    "    y_kmeans = kmeans.predict(X)\n",
    "\n",
    "    one_hot = np.eye(n_clusters)[y_kmeans]\n",
    "    print(one_hot.sum(axis=0))\n",
    "\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ground Truth Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = clustering(res_mat, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/model_profiles.json\", 'r') as f:\n",
    "    model_profiles = json.load(f)\n",
    "\n",
    "for i, m in enumerate(result_summary.index):\n",
    "    model_profiles[m]['gt_cluster'] = list(one_hot[i])\n",
    "\n",
    "with open(\"data/model_profiles.json\", 'w') as f:\n",
    "    json.dump(model_profiles, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = clustering(res_mat.T, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/dataset_profiles.json\", 'r') as f:\n",
    "    dataset_profiles = json.load(f)\n",
    "\n",
    "for i, d in enumerate(result_summary.columns):\n",
    "    dataset_profiles[d] = {}\n",
    "    dataset_profiles[d]['gt_cluster'] = list(one_hot[i])\n",
    "\n",
    "with open(\"data/dataset_profiles.json\", 'w') as f:\n",
    "    json.dump(dataset_profiles, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden States Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.config import ALL_DATASETS\n",
    "\n",
    "avg_hs = joblib.load(\"data/dataset_avg_hs_llava7B.pkl\")\n",
    "hs = []\n",
    "\n",
    "for data in ALL_DATASETS:\n",
    "    hs.append(avg_hs[data]['hs'])\n",
    "\n",
    "hs = np.array(hs)\n",
    "hs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = clustering(hs, 5)\n",
    "\n",
    "with open(\"data/dataset_profiles.json\", 'r') as f:\n",
    "    dataset_profiles = json.load(f)\n",
    "\n",
    "for i, d in enumerate(result_summary.columns):\n",
    "    if d not in dataset_profiles:\n",
    "        dataset_profiles[d] = {}\n",
    "    dataset_profiles[d]['hs_cluster'] = list(one_hot[i])\n",
    "\n",
    "with open(\"data/dataset_profiles.json\", 'w') as f:\n",
    "    json.dump(dataset_profiles, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Description Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "des_datasets = [\n",
    "'Instance Attributes',\n",
    " 'Emotion Recognition',\n",
    " 'Global Video Understanding',\n",
    " 'Chart Understanding',\n",
    " 'Landmark Recognition',\n",
    " 'Instances Counting',\n",
    " 'Action Prediction',\n",
    " 'Text Understanding',\n",
    " 'Text-to-Image Generation',\n",
    " 'Action Recognition',\n",
    " 'Instance Location',\n",
    " 'Instance Interaction',\n",
    " 'Scene Understanding',\n",
    " 'Instance Identity',\n",
    " 'Text-Image Creation',\n",
    " 'Visual Mathematics',\n",
    " 'Difference Spotting',\n",
    " 'Spatial Relation',\n",
    " 'Science Knowledge',\n",
    " 'Procedure Understanding',\n",
    " 'Visual Reasoning',\n",
    " 'In-Context Captioning',\n",
    " 'Meme Comprehension',\n",
    " 'Celebrity Recognition',\n",
    " 'Visual Referring Expression',\n",
    " 'Interleaved Image-Text Analysis',\n",
    " 'Next Image Prediction',\n",
    " 'Celebrity',\n",
    " 'Posters',\n",
    " 'Position',\n",
    " 'Scene',\n",
    " 'Commonsense Reasoning',\n",
    " 'Artwork',\n",
    " 'Landmark',\n",
    " 'Text Translation',\n",
    " 'Existence',\n",
    " 'Numerical Calculation',\n",
    " 'Count',\n",
    " 'Color',\n",
    " 'OCR',\n",
    " 'Code Reasoning',\n",
    " 'Social Relation',\n",
    " 'Object Localization',\n",
    " 'Future Prediction',\n",
    " 'Physical Property Reasoning',\n",
    " 'Attribute Comparison',\n",
    " 'Nature Relation',\n",
    " 'Action Recognition',\n",
    " 'Image Scene',\n",
    " 'Celebrity Recognition',\n",
    " 'OCR',\n",
    " 'Spatial Relationship',\n",
    " 'Structuralized Image-Text Understanding',\n",
    " 'Image Emotion',\n",
    " 'Function Reasoning',\n",
    " 'Identity Reasoning',\n",
    " 'Physical Relation',\n",
    " 'Image Style',\n",
    " 'Attribute Recognition',\n",
    " 'Image Quality',\n",
    " 'Image Topic',\n",
    " 'Social Relation',\n",
    " 'Object Localization',\n",
    " 'Future Prediction',\n",
    " 'Physical Property Reasoning',\n",
    " 'Attribute Comparison',\n",
    " 'Nature Relation',\n",
    " 'Action Recognition',\n",
    " 'Image Scene',\n",
    " 'Celebrity Recognition',\n",
    " 'OCR',\n",
    " 'Spatial Relationship',\n",
    " 'Structuralized Image-Text Understanding',\n",
    " 'Image Emotion',\n",
    " 'Function Reasoning',\n",
    " 'Identity Reasoning',\n",
    " 'Physical Relation',\n",
    " 'Image Style',\n",
    " 'Attribute Recognition',\n",
    " 'Image Quality',\n",
    " 'Image Topic',\n",
    " 'Mechanical Engineering',\n",
    " 'Basic Medical Science',\n",
    " 'Math',\n",
    " 'Pharmacy',\n",
    " 'Public Health',\n",
    " 'Physics',\n",
    " 'Energy and Power',\n",
    " 'Sociology',\n",
    " 'Art Theory',\n",
    " 'History',\n",
    " 'Materials',\n",
    " 'Geography',\n",
    " 'Chemistry',\n",
    " 'Electronics',\n",
    " 'Economics',\n",
    " 'Art',\n",
    " 'Accounting',\n",
    " 'Psychology',\n",
    " 'Architecture and Engineering',\n",
    " 'Manage',\n",
    " 'Clinical Medicine',\n",
    " 'Music',\n",
    " 'Finance',\n",
    " 'Marketing',\n",
    " 'Design',\n",
    " 'Literature',\n",
    " 'Biology',\n",
    " 'Diagnostics and Laboratory Medicine',\n",
    " 'Computer Science',\n",
    " 'Agriculture',\n",
    " 'Technology and Engineering',\n",
    " 'Business',\n",
    " 'Health and Medicine',\n",
    " 'Humanities and Social Sciences',\n",
    " 'Science',\n",
    " 'Arts and Design',\n",
    " 'Ecosystems',\n",
    " 'English Colonies in North America',\n",
    " 'State Capitals',\n",
    " 'Designing Experiments',\n",
    " 'Materials',\n",
    " 'Adaptations',\n",
    " 'Velocity, Acceleration, and Forces',\n",
    " 'Particle Motion and Energy',\n",
    " 'Geography',\n",
    " 'Magnets',\n",
    " 'Astronomy',\n",
    " 'Oceania: Geography',\n",
    " 'Weather and Climate',\n",
    " 'The Americas: Geography',\n",
    " 'Classification and Scientific Names',\n",
    " 'Engineering Practices',\n",
    " 'Atoms and Molecules',\n",
    " 'Scientific Names',\n",
    " 'Solutions',\n",
    " 'Maps',\n",
    " 'Genes to Traits',\n",
    " 'Physical Geography',\n",
    " 'Classification',\n",
    " 'Basic Economic Principles',\n",
    " 'Colonial America',\n",
    " '2D Count',\n",
    " '3D Distance',\n",
    " '2D Relation',\n",
    " '3D Depth',\n",
    " 'DECIMER: a hand-drawn molecule image dataset consisting of chemical structure as the images and their SMILES representation as the strings',\n",
    " 'Enrico: a topic modeling dataset for mobile UI screens',\n",
    " 'FaceEmotion: a classic dataset for facial expression recognition',\n",
    " 'Flickr30k: an image captioning dataset collected from Flickr',\n",
    " 'GQA: builds up on scene graph structures for reasoning questions',\n",
    " 'HatefulMemes: a challenge hosted by Meta to classify if a meme image along with its text caption describes hateful intentions',\n",
    " 'INAT: an image classification dataset for 5000 wildlife species of plants and animals',\n",
    " 'IRFL: an image-text dataset for figurative language understanding',\n",
    " 'MemeCaps: a meme captioning dataset',\n",
    " 'Memotion: sentiment classification, humor classification, and the scale of semantic classes',\n",
    " 'MMIMDB: a genre prediction dataset that consists of an image of the poster of the movie along with the plot',\n",
    " 'NewYorkerCartoon: collected from the weekly New Yorker magazine cartoon captioning contest, where readers are tasked to give a humorous caption for a cartoon image and the funniest captions are selected based on public votes',\n",
    " 'NLVR: image-text pairs for visual reasoning.  Images are created by generating objects and their properties randomly.',\n",
    " 'NLVR2: real-world photographs and captions for these photographs',\n",
    " 'NoCaps: a large scale image captioning dataset',\n",
    " 'OKVQA: a visual question-answering task that requires outside knowledge and reasoning to answer questions',\n",
    " 'OpenPath: sourced from tweets across 32 hashtag sub-specialty categories in pathology',\n",
    " 'PathVQA: a visual QA dataset based on pathology images',\n",
    " 'Resisc45: a land use dataset that involves land scene classification of images over 45 classes',\n",
    " 'Screen2Words: a mobile UI summarization dataset',\n",
    " 'Slake: a medical visual question-answering dataset',\n",
    " 'UCMerced: a dataset for land use classification which has 21 classes',\n",
    " 'VCR: commonsense reasoning skills in question answering over images.',\n",
    " 'VisualGenome: a visual question-answering dataset that grounds visual concepts to language. ',\n",
    " 'VQA: fine-grained recognition of objects and activities with some commonsense reasoning',\n",
    " 'VQARAD: a visual question-answering dataset over radiology images',\n",
    " 'Winoground: a dataset for visual linguistic compositional reasoning',\n",
    " 'Hallucination (Random selected categories)',\n",
    " 'Hallucination (Popular categories)',\n",
    " 'Hallucination (Adversarially selected categories)'\n",
    "]\n",
    "\n",
    "# 1. Load a pretrained Sentence Transformer model\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "# 2. Calculate embeddings by calling model.encode()\n",
    "embeddings = model.encode(des_datasets)\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = clustering(embeddings, 5)\n",
    "\n",
    "with open(\"data/dataset_profiles.json\", 'r') as f:\n",
    "    dataset_profiles = json.load(f)\n",
    "\n",
    "for i, d in enumerate(result_summary.columns):\n",
    "    if d not in dataset_profiles:\n",
    "        dataset_profiles[d] = {}\n",
    "    dataset_profiles[d]['des_cluster'] = list(one_hot[i])\n",
    "\n",
    "with open(\"data/dataset_profiles.json\", 'w') as f:\n",
    "    json.dump(dataset_profiles, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLIP\n",
    "import re\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "from utils.config import ALL_DATASETS\n",
    "\n",
    "dataset_rep = []\n",
    "for dataset in ALL_DATASETS:\n",
    "    task_name, bench_name = re.match(r\"(.*) \\((.*)\\)\", dataset).groups()\n",
    "    output_file = f\"./data/dataset_representation_clip/{task_name}_{bench_name}.pkl\"\n",
    "\n",
    "    data = joblib.load(output_file)\n",
    "    hs = [ins['hidden_states'] for ins in data]\n",
    "    hs = np.concatenate(hs)\n",
    "    print(dataset, hs.shape)\n",
    "    \n",
    "    dataset_rep.append(hs.mean(axis=0))\n",
    "\n",
    "dataset_rep = np.array(dataset_rep)\n",
    "print(dataset_rep.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = clustering(dataset_rep, 5)\n",
    "\n",
    "with open(\"data/dataset_profiles.json\", 'r') as f:\n",
    "    dataset_profiles = json.load(f)\n",
    "\n",
    "for i, d in enumerate(result_summary.columns):\n",
    "    if d not in dataset_profiles:\n",
    "        dataset_profiles[d] = {}\n",
    "    dataset_profiles[d]['clip_cluster'] = list(one_hot[i])\n",
    "\n",
    "with open(\"data/dataset_profiles.json\", 'w') as f:\n",
    "    json.dump(dataset_profiles, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model profile:  (108, 5)\n",
      "Load dataset profile:  (176, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((108, 5), (176, 5))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from method.matrix import MatrixManager\n",
    "\n",
    "mm = MatrixManager()\n",
    "\n",
    "model_profile = mm.get_model_profiles(['gt_cluster'])\n",
    "dataset_profile = mm.get_dataset_profiles(['gt_cluster'])\n",
    "\n",
    "model_profile.shape, dataset_profile.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_hs_profile = mm.get_dataset_profiles(['hs_cluster'])\n",
    "dataset_hs_profile.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_hs_profile = mm.get_dataset_profiles(['des_cluster'])\n",
    "dataset_hs_profile.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_hs_profile = mm.get_dataset_profiles(['clip_cluster'])\n",
    "dataset_hs_profile.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load dataset profile:  (176, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(176, 5)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_hs_profile = mm.get_dataset_profiles(['random'])\n",
    "dataset_hs_profile.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
